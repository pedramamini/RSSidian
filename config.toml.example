# RSSidian Configuration

[obsidian]
# Path to your Obsidian vault
vault_path = "~/Documents/Obsidian"

# Template for the output filename
# Available variables: {from_date}, {to_date}, {date_range}, {date}, {datetime}
filename_template = "RSS Digest {from_date} to {to_date}"

# Template for generated digest note
# Available variables: {date_range}, {summary_items}, {value_analysis}, {feed_stats}, {aggregated_summary}, {cost_summary}, {ingestion_date}
template = """# Feed Digest

## Aggregated Overview by Subject
{aggregated_summary}

## Article Summaries
{summary_items}

## Feed Statistics
{feed_stats}

## Cost Summary
{cost_summary}

Ingestion_Date:: {ingestion_date}
"""

[ai]
# AI provider selection - choose between "openrouter" or "anthropic"
provider = "openrouter"

[search]
# Search configuration options

# Length of context to include in search excerpts (in characters)
excerpt_length = 300

[openrouter]
# OpenRouter API configuration
# API key can also be set via RSSIDIAN_OPENROUTER_API_KEY environment variable
api_key = ""

# Enable or disable cost tracking for API calls
cost_tracking_enabled = true

# Model to use for topic detection and article processing
processing_model = "openai/gpt-4o"

# Sample size in characters for topic detection
topic_sample_size = 4096

# Model to use for summarization
# See https://openrouter.ai/docs for available models
model = "openai/gpt-4o"

# Prompt template for processing articles
# Available variables: {content}
prompt = """You are a helpful article summarizer.
Given the following article content, provide:
1. A concise 1-2 sentence summary of the key points
2. The most important takeaway or insight

Content:
{content}
"""

# Enable value analysis in output
# When enabled, each article will include a Value assessment
value_prompt_enabled = true

# Minimum quality tier to include in digest (S, A, B, C, D)
# Articles with lower quality tiers will be discarded
minimum_quality_tier = "B"

# Aggregator prompt template for generating a categorized overview of articles
# Available variables: {summaries}
aggregator_prompt = """You are an expert content curator and analyst.

Your task is to organize and summarize the following article summaries into a cohesive overview, categorized by subject matter.

Group the articles into clear categories such as Politics, Science, Technology, AI/GenAI, Programming, Business, Startups, Health, etc. based on their content.

For each category:
1. Provide a brief overview of the key themes or trends
2. List the most important articles with their titles (in markdown link format) and a 1-sentence description
3. Highlight any connections or contradictions between articles in the same category

Finally, provide a brief "Big Picture" section that identifies any cross-category trends or important developments.

Article Summaries:
{summaries}
"""

# Value analysis prompt template
# This prompt analyzes the content to determine its value density
# Available variables: {content}
value_prompt = """
IDENTITY and GOAL:

You are an ultra-wise and brilliant classifier and judge of content. You label
content with a comma-separated list of single-word labels and then give it a
quality rating.

Take a deep breath and think step by step about how to perform the following to
get the best outcome.

STEPS:

1. You label the content with as many of the following labels that apply based
on the content of the input. These labels go into a section called LABELS:. Do
not create any new labels. Only use these.

LABEL OPTIONS TO SELECT FROM (Select All That Apply):

Meaning
Future
Business
Tutorial
Podcast
Miscellaneous
Creativity
NatSec
CyberSecurity
AI
Essay
Video
Conversation
Optimization
Personal
Writing
Human3.0
Health
Technology
Education
Leadership
Mindfulness
Innovation
Culture
Productivity
Science
Philosophy

END OF LABEL OPTIONS

2. You then rate the content based on the number of ideas in the input (below
ten is bad, between 11 and 20 is good, and above 25 is excellent) combined with
how well it directly and specifically matches the THEMES of: human meaning, the
future of human meaning, human flourishing, the future of AI, AI's impact on
humanity, human meaning in a post-AI world, continuous human improvement,
enhancing human creative output, and the role of art and reading in enhancing
human flourishing.
3. Rank content significantly lower if it's interesting and/or high quality but
not directly related to the human aspects of the topics, e.g., math or science
that doesn't discuss human creativity or meaning. Content must be highly focused
human flourishing and/or human meaning to get a high score.
4. Also rate the content significantly lower if it's significantly political,
meaning not that it mentions politics but if it's overtly or secretly advocating
for populist or extreme political views.

You use the following rating levels:

S Tier (Must Consume Original Content Within a Week): 18+ ideas and/or STRONG
theme matching with the themes in STEP #2.
A Tier (Should Consume Original Content This Month): 15+ ideas and/or GOOD theme
matching with the THEMES in STEP #2.
B Tier (Consume Original When Time Allows): 12+ ideas and/or DECENT theme
matching with the THEMES in STEP #2.
C Tier (Maybe Skip It): 10+ ideas and/or SOME theme matching with the THEMES in
STEP #2.
D Tier (Definitely Skip It): Few quality ideas and/or little theme matching with
the THEMES in STEP #2.

5. Also provide a score between 1 and 100 for the overall quality ranking, where
a 1 has low quality ideas or ideas that don't match the topics in step 2, and a
100 has very high quality ideas that closely match the themes in step 2.
6. Score content significantly lower if it's interesting and/or high quality but
not directly related to the human aspects of the topics in THEMES, e.g., math or
science that doesn't discuss human creativity or meaning. Content must be highly
focused on human flourishing and/or human meaning to get a high score.
7. Score content VERY LOW if it doesn't include interesting ideas or any
relation to the topics in THEMES.

OUTPUT:

The output should look like the following:

ONE SENTENCE SUMMARY:

A one-sentence summary of the content and why it's compelling, in less than 30
words.

LABELS:

CyberSecurity, Writing, Health, Personal

RATING:

S Tier: (Must Consume Original Content Immediately)

Explanation: $$Explanation in 5 short bullets for why you gave that rating.$$

QUALITY SCORE:

$$The 1-100 quality score$$

Explanation: $$Explanation in 5 short bullets for why you gave that score.$$

OUTPUT FORMAT:

Your output is ONLY in JSON. The structure looks like this:

{{
    "one-sentence-summary": "The one-sentence summary.",
    "labels": "The labels that apply from the set of options above.",
    "rating:": "S Tier: (Must Consume Original Content This Week) (or whatever the
    rating is)",
    "rating-explanation:": "The explanation given for the rating.",
    "quality-score": "The numeric quality score",
    "quality-score-explanation": "The explanation for the quality score.",
}}

OUTPUT INSTRUCTIONS

• ONLY generate and use labels from the list above.
• ONLY OUTPUT THE JSON OBJECT ABOVE.
• Do not output the json``` container. Just the JSON object itself.

INPUT:

{content}
"""

[annoy]
# Path to vector index file
index_path = "~/.config/rssidian/annoy.idx"

# Number of trees (more = better accuracy but slower build)
n_trees = 10

# Distance metric (angular = cosine similarity)
metric = "angular"

[feeds]
# Default lookback period (in days) for RSS ingestion
default_lookback = 7

# Maximum articles to process per feed during ingestion
max_articles_per_feed = 25

# Settings for duplicate/similar article detection
similarity_threshold = 0.70  # Higher values mean stricter matching (0.70 = 70% similarity)

[anthropic]
# Anthropic OAuth configuration (when using ai.provider = "anthropic")
# Get these credentials from https://console.anthropic.com/

# OAuth client credentials (required for OAuth)
client_id = ""
client_secret = ""

# OAuth redirect URI (should match what you configure in Anthropic console)
redirect_uri = "http://localhost:8080/callback"

# Model configuration
model = "claude-3-5-sonnet-20241022"
processing_model = "claude-3-5-sonnet-20241022"

# System prompt for Claude (this identifies the application as Claude Code)
system_prompt = "You are Claude Code, Anthropic's official CLI for Claude."

# Token storage file (tokens will be saved here after OAuth authentication)
token_file = "~/.config/rssidian/anthropic_tokens.json"

# Optional: You can also set tokens via environment variables:
# RSSIDIAN_ANTHROPIC_CLIENT_ID
# RSSIDIAN_ANTHROPIC_CLIENT_SECRET
# RSSIDIAN_ANTHROPIC_ACCESS_TOKEN
# RSSIDIAN_ANTHROPIC_REFRESH_TOKEN

# Whether to analyze articles during ingestion for better performance
analyze_during_ingestion = true

